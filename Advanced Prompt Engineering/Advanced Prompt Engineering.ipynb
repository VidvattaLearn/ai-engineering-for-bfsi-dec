{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting langchain<br/>  Using cached langchain-1.2.0-py3-none-any.whl.metadata (4.9 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting langchain-openai<br/>  Using cached langchain_openai-1.1.6-py3-none-any.whl.metadata (2.6 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting langchain-core&lt;2.0.0,&gt;=1.2.1 (from langchain)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">  Using cached langchain_core-1.2.5-py3-none-any.whl.metadata (3.7 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting langgraph&lt;1.1.0,&gt;=1.0.2 (from langchain)<br/>  Using cached langgraph-1.0.5-py3-none-any.whl.metadata (7.4 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting pydantic&lt;3.0.0,&gt;=2.7.4 (from langchain)<br/>  Using cached pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting openai&lt;3.0.0,&gt;=1.109.1 (from langchain-openai)<br/>  Using cached openai-2.14.0-py3-none-any.whl.metadata (29 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting tiktoken&lt;1.0.0,&gt;=0.7.0 (from langchain-openai)<br/>  Using cached tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.7 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Requirement already satisfied: jsonpatch&lt;2.0.0,&gt;=1.33.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain) (1.33)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting langsmith&lt;1.0.0,&gt;=0.3.45 (from langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">  Using cached langsmith-0.5.1-py3-none-any.whl.metadata (15 kB)<br/>Requirement already satisfied: packaging&lt;26.0.0,&gt;=23.2.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain) (23.2)<br/>Requirement already satisfied: pyyaml&lt;7.0.0,&gt;=5.3.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain) (6.0.1)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting tenacity!=8.4.0,&lt;10.0.0,&gt;=8.1.0 (from langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain)<br/>  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)<br/>Requirement already satisfied: typing-extensions&lt;5.0.0,&gt;=4.7.0 in /opt/conda/lib/python3.11/site-packages (from langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain) (4.8.0)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting uuid-utils&lt;1.0,&gt;=0.12.0 (from langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain)<br/>  Using cached uuid_utils-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.1 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting langgraph-checkpoint&lt;4.0.0,&gt;=2.1.0 (from langgraph&lt;1.1.0,&gt;=1.0.2-&gt;langchain)<br/>  Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl.metadata (4.7 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting langgraph-prebuilt&lt;1.1.0,&gt;=1.0.2 (from langgraph&lt;1.1.0,&gt;=1.0.2-&gt;langchain)<br/>  Using cached langgraph_prebuilt-1.0.5-py3-none-any.whl.metadata (5.2 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting langgraph-sdk&lt;0.4.0,&gt;=0.3.0 (from langgraph&lt;1.1.0,&gt;=1.0.2-&gt;langchain)<br/>  Using cached langgraph_sdk-0.3.1-py3-none-any.whl.metadata (1.6 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting xxhash&gt;=3.5.0 (from langgraph&lt;1.1.0,&gt;=1.0.2-&gt;langchain)<br/>  Using cached xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)<br/>Requirement already satisfied: anyio&lt;5,&gt;=3.5.0 in /opt/conda/lib/python3.11/site-packages (from openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai) (4.10.0)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting distro&lt;2,&gt;=1.7.0 (from openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai)<br/>  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)<br/>Requirement already satisfied: httpx&lt;1,&gt;=0.23.0 in /opt/conda/lib/python3.11/site-packages (from openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai) (0.28.1)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting jiter&lt;1,&gt;=0.10.0 (from openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai)<br/>  Using cached jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Requirement already satisfied: sniffio in /opt/conda/lib/python3.11/site-packages (from openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai) (1.3.0)<br/>Requirement already satisfied: tqdm&gt;4 in /opt/conda/lib/python3.11/site-packages (from openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai) (4.66.1)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting typing-extensions&lt;5.0.0,&gt;=4.7.0 (from langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain)<br/>  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting annotated-types&gt;=0.6.0 (from pydantic&lt;3.0.0,&gt;=2.7.4-&gt;langchain)<br/>  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting pydantic-core==2.41.5 (from pydantic&lt;3.0.0,&gt;=2.7.4-&gt;langchain)<br/>  Using cached pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.3 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting typing-inspection&gt;=0.4.2 (from pydantic&lt;3.0.0,&gt;=2.7.4-&gt;langchain)<br/>  Using cached typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting regex&gt;=2022.1.18 (from tiktoken&lt;1.0.0,&gt;=0.7.0-&gt;langchain-openai)<br/>  Using cached regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)<br/>Requirement already satisfied: requests&gt;=2.26.0 in /opt/conda/lib/python3.11/site-packages (from tiktoken&lt;1.0.0,&gt;=0.7.0-&gt;langchain-openai) (2.31.0)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Requirement already satisfied: idna&gt;=2.8 in /opt/conda/lib/python3.11/site-packages (from anyio&lt;5,&gt;=3.5.0-&gt;openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai) (3.4)<br/>Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from httpx&lt;1,&gt;=0.23.0-&gt;openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai) (2023.7.22)<br/>Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.11/site-packages (from httpx&lt;1,&gt;=0.23.0-&gt;openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai) (1.0.9)<br/>Requirement already satisfied: h11&gt;=0.16 in /opt/conda/lib/python3.11/site-packages (from httpcore==1.*-&gt;httpx&lt;1,&gt;=0.23.0-&gt;openai&lt;3.0.0,&gt;=1.109.1-&gt;langchain-openai) (0.16.0)<br/>Requirement already satisfied: jsonpointer&gt;=1.9 in /opt/conda/lib/python3.11/site-packages (from jsonpatch&lt;2.0.0,&gt;=1.33.0-&gt;langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain) (2.4)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting ormsgpack&gt;=1.12.0 (from langgraph-checkpoint&lt;4.0.0,&gt;=2.1.0-&gt;langgraph&lt;1.1.0,&gt;=1.0.2-&gt;langchain)<br/>  Using cached ormsgpack-1.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting orjson&gt;=3.10.1 (from langgraph-sdk&lt;0.4.0,&gt;=0.3.0-&gt;langgraph&lt;1.1.0,&gt;=1.0.2-&gt;langchain)<br/>  Using cached orjson-3.11.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting requests-toolbelt&gt;=1.0.0 (from langsmith&lt;1.0.0,&gt;=0.3.45-&gt;langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Collecting zstandard&gt;=0.23.0 (from langsmith&lt;1.0.0,&gt;=0.3.45-&gt;langchain-core&lt;2.0.0,&gt;=1.2.1-&gt;langchain)<br/>  Using cached zstandard-0.25.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.3 kB)<br/>Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /opt/conda/lib/python3.11/site-packages (from requests&gt;=2.26.0-&gt;tiktoken&lt;1.0.0,&gt;=0.7.0-&gt;langchain-openai) (3.3.0)<br/>Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests&gt;=2.26.0-&gt;tiktoken&lt;1.0.0,&gt;=0.7.0-&gt;langchain-openai) (2.0.7)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Using cached langchain-1.2.0-py3-none-any.whl (102 kB)<br/>Using cached langchain_openai-1.1.6-py3-none-any.whl (84 kB)<br/>Using cached langchain_core-1.2.5-py3-none-any.whl (484 kB)<br/>Using cached langgraph-1.0.5-py3-none-any.whl (157 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Using cached openai-2.14.0-py3-none-any.whl (1.1 MB)<br/>Using cached pydantic-2.12.5-py3-none-any.whl (463 kB)<br/>Using cached pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Using cached tiktoken-0.12.0-cp311-cp311-manylinux_2_28_x86_64.whl (1.2 MB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)<br/>Using cached distro-1.9.0-py3-none-any.whl (20 kB)<br/>Using cached jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (364 kB)<br/>Using cached langgraph_checkpoint-3.0.1-py3-none-any.whl (46 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Using cached langgraph_prebuilt-1.0.5-py3-none-any.whl (35 kB)<br/>Using cached langgraph_sdk-0.3.1-py3-none-any.whl (66 kB)<br/>Using cached langsmith-0.5.1-py3-none-any.whl (275 kB)<br/>Using cached regex-2025.11.3-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (800 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)<br/>Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)<br/>Using cached typing_inspection-0.4.2-py3-none-any.whl (14 kB)<br/>Using cached uuid_utils-0.12.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (343 kB)<br/>Using cached xxhash-3.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (193 kB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Using cached orjson-3.11.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)<br/>Using cached ormsgpack-1.12.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (211 kB)<br/>Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)<br/>Using cached zstandard-0.25.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (5.6 MB)<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Installing collected packages: zstandard, xxhash, uuid-utils, typing-extensions, tenacity, regex, ormsgpack, orjson, jiter, distro, annotated-types, typing-inspection, tiktoken, requests-toolbelt, pydantic-core, pydantic, openai, langsmith, langgraph-sdk, langchain-core, langgraph-checkpoint, langchain-openai, langgraph-prebuilt, langgraph, langchain<br/>  Attempting uninstall: zstandard<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">    Found existing installation: zstandard 0.21.0<br/>    Uninstalling zstandard-0.21.0:<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">      Successfully uninstalled zstandard-0.21.0<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">  Attempting uninstall: typing-extensions<br/>    Found existing installation: typing_extensions 4.8.0<br/>    Uninstalling typing_extensions-4.8.0:<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">      Successfully uninstalled typing_extensions-4.8.0<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Successfully installed annotated-types-0.7.0 distro-1.9.0 jiter-0.12.0 langchain-1.2.0 langchain-core-1.2.5 langchain-openai-1.1.6 langgraph-1.0.5 langgraph-checkpoint-3.0.1 langgraph-prebuilt-1.0.5 langgraph-sdk-0.3.1 langsmith-0.5.1 openai-2.14.0 orjson-3.11.5 ormsgpack-1.12.1 pydantic-2.12.5 pydantic-core-2.41.5 regex-2025.11.3 requests-toolbelt-1.0.0 tenacity-9.1.2 tiktoken-0.12.0 typing-extensions-4.15.0 typing-inspection-0.4.2 uuid-utils-0.12.0 xxhash-3.6.0 zstandard-0.25.0<br/></pre></div>"
          },
          "execution_count": 1,
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"2024-12-01-preview\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-agents-sept-cohort-resource.cognitiveservices.azure.com/\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"2U2P8vqX0UxejqEYRgn31WOSIxM5h3gj7UjIZkaojNjji7wycKDwJQQJ99BJAC77bzfXJ3w3AAAAACOGBt84\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "  deployment_name = \"gpt-4.1\",\n",
        "  temperature=1,\n",
        "  top_p=0.8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = llm.invoke('tell me about ai agents in 10 words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'AI agents autonomously perceive, reason, and act to achieve goals.'</pre>"
          },
          "execution_count": 7,
          "metadata": {}
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'AI agents: autonomous systems that perceive, reason, and act intelligently.'</pre>"
          },
          "execution_count": 17,
          "metadata": {}
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'AI agents are autonomous systems performing tasks, learning, and adapting.'</pre>"
          },
          "execution_count": 20,
          "metadata": {}
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'AI agents autonomously perceive, reason, act, and learn to solve tasks.'</pre>"
          },
          "execution_count": 23,
          "metadata": {}
        }
      ],
      "source": [
        "# temperature = 0\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'AI agents autonomously perceive, reason, act, and learn to solve tasks.'</pre>"
          },
          "execution_count": 26,
          "metadata": {}
        }
      ],
      "source": [
        "# temperature = 0\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'AI agents autonomously perceive, reason, act, and learn to solve tasks.'</pre>"
          },
          "execution_count": 29,
          "metadata": {}
        }
      ],
      "source": [
        "# temperature = 0\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'AI agents autonomously perceive, reason, act, and learn to solve tasks.'</pre>"
          },
          "execution_count": 32,
          "metadata": {}
        }
      ],
      "source": [
        "# temperature = 0\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'AI agents autonomously perform tasks, learn, and interact with environments.'</pre>"
          },
          "execution_count": 35,
          "metadata": {}
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'AI agents act autonomously, solve tasks, learn, and interact intelligently.'</pre>"
          },
          "execution_count": 40,
          "metadata": {}
        }
      ],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "  deployment_name = \"gpt-4.1\",\n",
        "  temperature=1,\n",
        "  top_p=0.8,\n",
        "  # max_tokens=5\n",
        ")\n",
        "\n",
        "response = llm.invoke('tell me about ai agents in 10 words')\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">```python<br/>[<br/>    &quot;Unlock Insights: New Global Consumer Trends Report&quot;,<br/>    &quot;Just Released: Premium Report on Consumer Trends&quot;,<br/>    &quot;Discover What&#x2019;s Next: Global Consumer Trends 2024&quot;<br/>]<br/>```<br/></pre></div>"
          },
          "execution_count": 42,
          "metadata": {}
        }
      ],
      "source": [
        "# zero shot \n",
        "resposne = llm.invoke(\"\"\"\n",
        "Write three short, punchy email subject lines to announce the launch of a new premium research report on global consumer trends. \n",
        "Keep them ≤ 60 characters and professional. this will be processed using python so give it in list form\n",
        "\"\"\")\n",
        "print(resposne.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">1. Uncover Insights: Global Consumer Trends Report  <br/>2. Download the Latest Global Consumer Trends Report  <br/>3. New Report &#x2014; Shape Strategy with Global Trends<br/></pre></div>"
          },
          "execution_count": 43,
          "metadata": {}
        }
      ],
      "source": [
        "few_shot_prompts = \"\"\"\n",
        "Example 1:\n",
        "Product: \"Holiday Shopping Index\"\n",
        "Subjects:\n",
        "- \"Holiday Shopping Index — What Changed\"\n",
        "- \"Top Holiday Trends You Need to Know\"\n",
        "- \"New: 2025 Holiday Shopping Index\"\n",
        "\n",
        "Example 2:\n",
        "Product: \"Ad Effectiveness Toolkit\"\n",
        "Subjects:\n",
        "- \"Boost ROI: Ad Effectiveness Toolkit\"\n",
        "- \"New Toolkit — Measure Ad Impact Faster\"\n",
        "- \"Get the Ad Effectiveness Playbook\"\n",
        "\n",
        "Example 3:\n",
        "Product: \"Gen Z Buying Signals\"\n",
        "Subjects:\n",
        "- \"Gen Z Buying Signals — Download Now\"\n",
        "- \"What Gen Z Wants in 2025\"\n",
        "- \"New Report: Gen Z Purchase Triggers\"\n",
        "\n",
        "Now: Product: \"Global Consumer Trends Report\"\n",
        "Write three short, punchy email subject lines. Keep them ≤ 60 characters, professional, and include a strong action word.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "resposne = llm.invoke(few_shot_prompts)\n",
        "print(resposne.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">- AI transforms industries with smarter, efficient systems  <br/>- Used in healthcare for diagnostics and personalized care  <br/>- Applied in finance for fraud detection and automated trading<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">```python<br/>def sum_even_numbers(numbers):<br/>    return sum(num for num in numbers if num % 2 == 0)<br/>```<br/></pre></div>"
          },
          "execution_count": 44,
          "metadata": {}
        }
      ],
      "source": [
        "# Summarization\n",
        "context = \"\"\"Input Text: Artificial Intelligence (AI) has become a transformative technology in numerous industries. Its applications range from healthcare, where AI is used to improve diagnostics and personalize patient care, to finance, where it helps in fraud detection and automated trading. As AI continues to evolve, \n",
        "it is poised to revolutionize traditional industries, creating smarter, more efficient systems. \"\"\"\n",
        "\n",
        "prompt = \"Summarize in 3 bullet points. each bullet point should be less than 100 characters\"\n",
        "\n",
        "\n",
        "resposne = llm.invoke(context + '\\n' + prompt)\n",
        "print(resposne.content)\n",
        "\n",
        "\n",
        "## Code Generation\n",
        "\n",
        "prompt  = \"Write a Python function that takes a list of integers and returns the sum of all even numbers, only respond with a code\"\n",
        "\n",
        "resposne = llm.invoke(prompt)\n",
        "print(resposne.content)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Enter the question : what are crisis impacts</pre></div><div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Enter the question : what leads to temparature rises</pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Based on the context, the **impacts of the global climate change crisis** include:<br/><br/>- **Rising temperatures:** Average global temperatures increase, leading to heatwaves and altered weather patterns.<br/>- **More severe weather patterns:** Increased frequency and intensity of storms, floods, droughts, and wildfires.<br/>- **Disruptions in ecosystems:** Changes in habitats threaten plant and animal species, causing loss of biodiversity and affecting food chains.<br/><br/>Additional impacts may include:<br/>- **Melting glaciers and rising sea levels:** Threatening coastal communities and infrastructure.<br/>- **Food and water insecurity:** Reduced agricultural yields and freshwater availability.<br/>- **Health risks:** Spread of diseases, heat-related illnesses, and air quality deterioration.<br/>- **Economic losses:** Damage to property, increased costs for disaster response, and negative effects on industries such as agriculture, fishing, and tourism.<br/><br/>In summary, the crisis affects the environment, society, and economies worldwide.<br/></pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Temperature rises are primarily caused by increased concentrations of greenhouse gases in the atmosphere. Human activities, especially the burning of fossil fuels (such as coal, oil, and natural gas), release greenhouse gases like carbon dioxide (CO&#x2082;), methane (CH&#x2084;), and nitrous oxide (N&#x2082;O). These gases trap heat from the sun in the Earth&apos;s atmosphere, leading to global warming and rising temperatures.<br/></pre></div><div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Enter the question : null</pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">It looks like you&apos;ve provided a context statement about climate change. How can I assist you further? Do you need a summary, explanation, quiz questions, or something else related to this context?<br/></pre></div><div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Enter the question : null</pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">It looks like you&#x2019;ve provided a context about the global climate change crisis and noted &quot;None.&quot; Could you clarify what you need? For example, are you looking for a summary, an explanation, quiz questions, or something else related to this context? Please let me know how I can assist!<br/></pre></div><div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Enter the question : null</pre></div><div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Enter the question : null</pre></div>\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">It looks like you&apos;ve provided a context about the global climate change crisis and indicated &quot;None&quot; as your prompt. How can I assist you further with this information? For example, would you like a summary, an explanation, a quiz question, or help developing an essay or presentation based on this context? Please let me know how you&apos;d like to proceed!<br/></pre></div><span style=\"color:#A00\">---------------------------------------------------------------------------</span></br><span style=\"color:#A00\">KeyboardInterrupt</span>                         Traceback (most recent call last)</br>Cell <span style=\"color:#0A0\">In[45], line 8</span><br/><b><span style=\"color:#0A0\">      3</span></b> question <span style=\"color:#626262\">=<span style=\"color:#000\"> <span style=\"color:#af0000\">&quot;<span style=\"color:#000\"><span style=\"color:#af0000\">Question: What are the primary causes of climate change?<span style=\"color:#000\"><span style=\"color:#af0000\">&quot;<span style=\"color:#000\"><br/><b><span style=\"color:#0A0\">      6</span></b></span></span></span></span></span></span></span></span> <blink><b>while<span style=\"color:#000\"></span></b></blink> (<blink><b>True<span style=\"color:#000\"></span></b></blink>):<br/><span style=\"color:#0A0\">----&gt; 8</span>   question <span style=\"color:#626262\">=<span style=\"color:#000\"> <blink><span style=\"background-color:#A50\">input<span style=\"color:#000\"><span style=\"background-color:#fff\"><span style=\"background-color:#A50\">(<span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">&quot;<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">Enter the question<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">&quot;<span style=\"color:#000\"><span style=\"background-color:#fff\"><span style=\"background-color:#A50\">)<span style=\"background-color:#fff\"><br/><b><span style=\"color:#0A0\">      9</span></b></span></span></span></span></span></blink></span></span></span></blink></span></span></span></blink></span></span></span></span></span></blink></span></span>   context <span style=\"color:#626262\">=<span style=\"color:#000\"> <span style=\"color:#af0000\">f<span style=\"color:#000\"><span style=\"color:#af0000\">&quot;&quot;&quot;<span style=\"color:#000\"><span style=\"color:#af0000\">Context: <span style=\"color:#000\"><span style=\"color:#af0000\">&quot;<span style=\"color:#000\"><span style=\"color:#af0000\">The global climate change crisis is primarily driven by human activities, including the burning of fossil fuels which <span style=\"color:#000\"><br/><b><span style=\"color:#0A0\">     10</span></b></span></span></span></span></span></span></span></span></span></span></span></span> <span style=\"color:#af0000\">  increases the concentration of greenhouse gases in the atmosphere. This leads to rising temperatures, more severe weather patterns,<span style=\"color:#000\"><br/><b><span style=\"color:#0A0\">     11</span></b></span></span> <span style=\"color:#af0000\">  and disruptions in ecosystems.<span style=\"color:#000\"><span style=\"color:#af0000\">&quot;<span style=\"color:#000\"><br/><b><span style=\"color:#0A0\">     12</span></b></span></span></span></span> <span style=\"color:#af0000\">  <span style=\"color:#000\"><br/><b><span style=\"color:#0A0\">     13</span></b></span></span> <span style=\"color:#af0000\">  <span style=\"color:#000\"><blink><b>{<span style=\"color:#000\"></span></b></blink></span></span>question<blink><b>}<span style=\"color:#000\"></span></b></blink><span style=\"color:#af0000\">&quot;&quot;&quot;<span style=\"color:#000\"><br/><b><span style=\"color:#0A0\">     15</span></b></span></span>   resposne <span style=\"color:#626262\">=<span style=\"color:#000\"> llm<span style=\"color:#626262\">.<span style=\"color:#000\">invoke(context)<br/></span></span></span></span></br>File <span style=\"color:#0A0\">/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py:1202</span>, in <span style=\"color:#0AA\">Kernel.raw_input</span><span style=\"color:#00A\">(self, prompt)</span><br/><b><span style=\"color:#0A0\">   1200</span></b>     msg <span style=\"color:#626262\">=<span style=\"color:#000\"> <span style=\"color:#af0000\">&quot;<span style=\"color:#000\"><span style=\"color:#af0000\">raw_input was called, but this frontend does not support input requests.<span style=\"color:#000\"><span style=\"color:#af0000\">&quot;<span style=\"color:#000\"><br/><b><span style=\"color:#0A0\">   1201</span></b></span></span></span></span></span></span></span></span>     <blink><b>raise<span style=\"color:#000\"></span></b></blink> StdinNotImplementedError(msg)<br/><span style=\"color:#0A0\">-&gt; 1202</span> <blink><b>return<span style=\"color:#000\"></span></b></blink> <blink><span style=\"background-color:#A50\">self<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">.<span style=\"color:#000\"><span style=\"background-color:#fff\"><span style=\"background-color:#A50\">_input_request<span style=\"background-color:#fff\"><span style=\"background-color:#A50\">(<span style=\"background-color:#fff\"><br/><b><span style=\"color:#0A0\">   1203</span></b></span></span></span></span></span></span></span></blink></span></span></span></blink> <span style=\"background-color:#A50\">    <span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">str<span style=\"color:#000\"><span style=\"background-color:#fff\"><span style=\"background-color:#A50\">(<span style=\"background-color:#fff\"><span style=\"background-color:#A50\">prompt<span style=\"background-color:#fff\"><span style=\"background-color:#A50\">)<span style=\"background-color:#fff\"><span style=\"background-color:#A50\">,<span style=\"background-color:#fff\"><br/><b><span style=\"color:#0A0\">   1204</span></b></span></span></span></span></span></span></span></span></span></span></span></blink></span></span> <span style=\"background-color:#A50\">    <span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">self<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">.<span style=\"color:#000\"><span style=\"background-color:#fff\"><span style=\"background-color:#A50\">_parent_ident<span style=\"background-color:#fff\"><span style=\"background-color:#A50\">[<span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">&quot;<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">shell<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">&quot;<span style=\"color:#000\"><span style=\"background-color:#fff\"><span style=\"background-color:#A50\">]<span style=\"background-color:#fff\"><span style=\"background-color:#A50\">,<span style=\"background-color:#fff\"><br/><b><span style=\"color:#0A0\">   1205</span></b></span></span></span></span></span></span></span></blink></span></span></span></blink></span></span></span></blink></span></span></span></span></span></span></span></blink></span></span></span></blink></span></span> <span style=\"background-color:#A50\">    <span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">self<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">.<span style=\"color:#000\"><span style=\"background-color:#fff\"><span style=\"background-color:#A50\">get_parent<span style=\"background-color:#fff\"><span style=\"background-color:#A50\">(<span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">&quot;<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">shell<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">&quot;<span style=\"color:#000\"><span style=\"background-color:#fff\"><span style=\"background-color:#A50\">)<span style=\"background-color:#fff\"><span style=\"background-color:#A50\">,<span style=\"background-color:#fff\"><br/><b><span style=\"color:#0A0\">   1206</span></b></span></span></span></span></span></span></span></blink></span></span></span></blink></span></span></span></blink></span></span></span></span></span></span></span></blink></span></span></span></blink></span></span> <span style=\"background-color:#A50\">    <span style=\"background-color:#fff\"><span style=\"background-color:#A50\">password<span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\">=<span style=\"color:#000\"><span style=\"background-color:#fff\"><blink><span style=\"background-color:#A50\"><b>False<span style=\"color:#000\"><span style=\"background-color:#fff\"></span></span></b></span></blink></span></span></span></blink></span></span></span></span><span style=\"background-color:#A50\">,<span style=\"background-color:#fff\"><br/><b><span style=\"color:#0A0\">   1207</span></b></span></span> <span style=\"background-color:#A50\"><span style=\"background-color:#fff\"><span style=\"background-color:#A50\">)<span style=\"background-color:#fff\"><br/></span></span></span></span></br>File <span style=\"color:#0A0\">/opt/conda/lib/python3.11/site-packages/ipykernel/kernelbase.py:1245</span>, in <span style=\"color:#0AA\">Kernel._input_request</span><span style=\"color:#00A\">(self, prompt, ident, parent, password)</span><br/><b><span style=\"color:#0A0\">   1242</span></b> <blink><b>except<span style=\"color:#000\"></span></b></blink> <blink><b>KeyboardInterrupt<span style=\"color:#000\"></span></b></blink>:<br/><b><span style=\"color:#0A0\">   1243</span></b>     <blink><i># re-raise KeyboardInterrupt, to truncate traceback<span style=\"color:#000\"></span></i></blink><br/><b><span style=\"color:#0A0\">   1244</span></b>     msg <span style=\"color:#626262\">=<span style=\"color:#000\"> <span style=\"color:#af0000\">&quot;<span style=\"color:#000\"><span style=\"color:#af0000\">Interrupted by user<span style=\"color:#000\"><span style=\"color:#af0000\">&quot;<span style=\"color:#000\"><br/></span></span></span></span></span></span></span></span><span style=\"color:#0A0\">-&gt; 1245</span>     <blink><b>raise<span style=\"color:#000\"></span></b></blink> <blink><b>KeyboardInterrupt<span style=\"color:#000\"></span></b></blink>(msg) <blink><b>from<span style=\"color:#000\"></span></b></blink> <blink><b>None<span style=\"color:#000\"></span></b></blink><br/><b><span style=\"color:#0A0\">   1246</span></b> <blink><b>except<span style=\"color:#000\"></span></b></blink> <blink><b>Exception<span style=\"color:#000\"></span></b></blink>:<br/><b><span style=\"color:#0A0\">   1247</span></b>     <span style=\"color:#008700\">self<span style=\"color:#000\"><span style=\"color:#626262\">.<span style=\"color:#000\">log<span style=\"color:#626262\">.<span style=\"color:#000\">warning(<span style=\"color:#af0000\">&quot;<span style=\"color:#000\"><span style=\"color:#af0000\">Invalid Message:<span style=\"color:#000\"><span style=\"color:#af0000\">&quot;<span style=\"color:#000\">, exc_info<span style=\"color:#626262\">=<span style=\"color:#000\"><blink><b>True<span style=\"color:#000\"></span></b></blink></span></span></span></span></span></span></span></span></span></span></span></span></span></span>)<br/></br><span style=\"color:#A00\">KeyboardInterrupt</span>: Interrupted by user</br>"
          },
          "execution_count": 45,
          "metadata": {}
        }
      ],
      "source": [
        "# Question Answering\n",
        "\n",
        "question = \"Question: What are the primary causes of climate change?\"\n",
        "\n",
        "\n",
        "while (True):\n",
        "  \n",
        "  question = input(\"Enter the question\")\n",
        "  context = f\"\"\"Context: \"The global climate change crisis is primarily driven by human activities, including the burning of fossil fuels which \n",
        "  increases the concentration of greenhouse gases in the atmosphere. This leads to rising temperatures, more severe weather patterns,\n",
        "  and disruptions in ecosystems.\"\n",
        "  \n",
        "  {question}\"\"\"\n",
        "\n",
        "  resposne = llm.invoke(context)\n",
        "  print(resposne.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">**Name:** John Smith  <br/>**Date of Birth:** April 15, 1985  <br/>**Job Title:** Software Engineer  <br/>**Company:** InnovateTech<br/></pre></div>"
          },
          "execution_count": 56,
          "metadata": {}
        }
      ],
      "source": [
        "# Data Extraction\n",
        "\n",
        "prompt = \"\"\"Input: \"John Smith, born on April 15, 1985, works as a software engineer at InnovateTech, located at 1234 Tech Lane, \n",
        "San Francisco, CA.\" Prompt: \n",
        "Extract the person's name, date of birth, job title, and company from the following text.\"\"\"\n",
        "\n",
        "resposne = llm.invoke(prompt)\n",
        "print(resposne.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>AIMessage(content='**Name:** John Smith  \\n**Date of Birth:** April 15, 1985  \\n**Job Title:** Software Engineer  \\n**Company:** InnovateTech', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 33, 'prompt_tokens': 69, 'total_tokens': 102, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-4.1-2025-04-14', 'system_fingerprint': 'fp_f99638a8d7', 'id': 'chatcmpl-CrHZavpdwVip5q7eh5XWC3ZuKmf2i', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'jailbreak': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'detected': False, 'filtered': False}, 'protected_material_text': {'detected': False, 'filtered': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}, id='lc_run--019b5e60-f0bb-76f0-9891-1e0e250ae48f-0', usage_metadata={'input_tokens': 69, 'output_tokens': 33, 'total_tokens': 102, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})</pre>"
          },
          "execution_count": 57,
          "metadata": {}
        }
      ],
      "source": [
        "resposne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">person_name=&apos;John Smith&apos; date_of_birth=&apos;April 15, 1985&apos; job_title=&apos;Software Engineer&apos; company=&apos;InnovateTech&apos; joining_date=&apos;&apos;<br/></pre></div>"
          },
          "execution_count": 52,
          "metadata": {}
        }
      ],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "class PersonDetails(BaseModel):\n",
        "    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n",
        "    person_name: str = Field(description=\"Name of the person\")\n",
        "    date_of_birth: str = Field(description=\"date of birth\")\n",
        "    job_title: str = Field(\"Job Title\")\n",
        "    company: str = Field(\"Company\")\n",
        "    joining_date: str = Field(\"get joining date from the text, it should be a date\")\n",
        "\n",
        "\n",
        "model_with_structured_output = llm.with_structured_output(PersonDetails)\n",
        "\n",
        "response = model_with_structured_output.invoke(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'April 15, 1985'</pre>"
          },
          "execution_count": 54,
          "metadata": {}
        }
      ],
      "source": [
        "response.date_of_birth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">people=[Person(name=&apos;Rajesh Malhotra&apos;, title=&apos;Mr&apos;), Person(name=&apos;Sharmila Sharma&apos;, title=&apos;Miss&apos;)]<br/></pre></div>"
          },
          "execution_count": 55,
          "metadata": {}
        }
      ],
      "source": [
        "class Person(BaseModel):\n",
        "    name: str = Field(description=\"name of the person being discussed\")\n",
        "    title: str = Field(description=\"job title of the person being discussed\")\n",
        "\n",
        "# 2. Define the outer model, which includes a list of the nested model\n",
        "class People(BaseModel):\n",
        "    people: list[Person] = Field(description=\"a list of people and their related fields mentioned in the text\")\n",
        "\n",
        "model_with_structured_output = llm.with_structured_output(People)\n",
        "\n",
        "response = model_with_structured_output.invoke(\"two people mr rajesh malhotra and miss sharmila sharma went to party\")\n",
        "print(response)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Let&apos;s analyze the customer&apos;s financial profile:<br/><br/>- **Age:** 42  <br/>- **Annual Income:** &#x20B9;18,00,000  <br/>- **Investment experience:** 8 years  <br/>- **Primary investment goal:** Retirement corpus  <br/><br/>**Risk profile classification criteria:**<br/>- **Conservative:** Income &lt; &#x20B9;5,00,000 **or** no investment experience<br/>- **Moderate:** Income &#x20B9;5,00,000&#x2013;&#x20B9;15,00,000 **or** investment experience &lt; 5 years<br/>- **Aggressive:** Income &gt; &#x20B9;15,00,000 **and** investment experience &#x2265; 5 years<br/><br/>---<br/><br/>### Evaluation:<br/><br/>- **Income:** &#x20B9;18,00,000 (**&gt; &#x20B9;15,00,000**)<br/>- **Investment experience:** 8 years (**&#x2265; 5 years**)<br/><br/>Both conditions for **Aggressive** are met.<br/><br/>---<br/><br/>## **Customer&apos;s risk profile:**  <br/>**Aggressive**<br/></pre></div>"
          },
          "execution_count": 63,
          "metadata": {}
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "cot_prompt = '''\n",
        "Given the following customer's financial profile:\n",
        "{profile}  \n",
        "\n",
        "Risk profile classification:\n",
        "- Conservative: Income < ₹5,00,000 or no investment experience\n",
        "- Moderate: Income ₹5,00,000–₹15,00,000 or investment experience < 5 years\n",
        "- Aggressive: Income > ₹15,00,000 and investment experience ≥ 5 years\n",
        "\n",
        "Let’s reason step by step:\n",
        "1. Check income threshold.\n",
        "2. Check investment experience.\n",
        "3. Apply both criteria to classify.\n",
        "\n",
        "\n",
        "\n",
        "What is the customer's risk profile?\n",
        "'''\n",
        "\n",
        "cot_template = PromptTemplate(\n",
        "    input_variables=[\"profile\"],\n",
        "    template=cot_prompt\n",
        ")\n",
        "\n",
        "cust_profile = \"\"\"Profile 1:\n",
        "- Age: 42  \n",
        "- Annual Income: ₹18,00,000  \n",
        "- Investment experience: 8 years  \n",
        "- Primary investment goal: Retirement corpus\"\"\"\n",
        "\n",
        "llm_cot_profile = cot_template | llm\n",
        "\n",
        "response = llm_cot_profile.invoke({'profile': cust_profile})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">**Customer&#x2019;s Financial Profile Recap:**  <br/>- Age: 42  <br/>- Annual Income: &#x20B9;18,00,000  <br/>- Investment experience: 8 years  <br/>- Primary goal: Retirement corpus  <br/><br/>**Risk Profile Classification Criteria:**  <br/>- **Conservative:** Income &lt; &#x20B9;5,00,000 OR no investment experience  <br/>- **Moderate:** Income &#x20B9;5,00,000&#x2013;&#x20B9;15,00,000 OR investment experience &lt; 5 years  <br/>- **Aggressive:** Income &gt; &#x20B9;15,00,000 AND investment experience &#x2265; 5 years  <br/><br/>### Step 1: Classify the Risk Profile<br/><br/>- **Income:** &#x20B9;18,00,000 (&gt; &#x20B9;15,00,000)<br/>- **Investment experience:** 8 years (&#x2265; 5 years)<br/><br/>**Both conditions for Aggressive are met.**  <br/>**Customer&#x2019;s Risk Profile:** **Aggressive**<br/><br/>---<br/><br/>### Step 2: Generate 5 Different Strategies for Evaluating the Risk Profile<br/><br/>#### **Strategy 1: Income &amp; Experience Matrix**<br/>- Create a matrix matching income and investment experience ranges to risk profiles.<br/>- Place the customer in the matrix to determine their risk category.<br/><br/>#### **Strategy 2: Weighted Scoring Model**<br/>- Assign weights to income and investment experience (e.g., 60% income, 40% experience).<br/>- Calculate a composite score to classify risk.<br/><br/>#### **Strategy 3: Rule-based Filtering**<br/>- Apply each rule in sequence:<br/>  1. Is income &lt; &#x20B9;5,00,000? No.<br/>  2. Is investment experience 0? No.<br/>  3. Is income &#x20B9;5,00,000&#x2013;&#x20B9;15,00,000? No.<br/>  4. Is investment experience &lt; 5 years? No.<br/>  5. Is income &gt; &#x20B9;15,00,000 **AND** experience &#x2265; 5 years? Yes &#x2192; Aggressive.<br/><br/>#### **Strategy 4: Decision Tree**<br/>- Build a decision tree with income and experience as branches.<br/>- Traverse the tree based on customer data to reach the classification.<br/><br/>#### **Strategy 5: Algorithmic Evaluation**<br/>- Programmatically check each condition using logical operators.<br/>- Output risk profile based on which conditions are satisfied.<br/><br/>---<br/><br/>### Step 3: Pick the Best Strategy<br/><br/>**Best Strategy:** **Rule-based Filtering (Strategy 3)**<br/><br/>**Why?**  <br/>- Simple, transparent, and directly applies the provided criteria without ambiguity.<br/>- Easy to explain to stakeholders and implement in compliance processes.<br/><br/>---<br/><br/>## **Final Answer**<br/><br/>**The customer&apos;s risk profile is: AGGRESSIVE.**<br/><br/>**Best evaluation strategy:** Rule-based filtering, as it is clear, direct, and applies all classification rules sequentially to reach the correct conclusion.<br/></pre></div>"
          },
          "execution_count": 65,
          "metadata": {}
        }
      ],
      "source": [
        "# Self Consistency\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "cot_prompt = '''\n",
        "You are financial risk expert\n",
        "Given the following customer's financial profile:\n",
        "{profile}  \n",
        "\n",
        "Risk profile classification:\n",
        "- Conservative: Income < ₹5,00,000 or no investment experience\n",
        "- Moderate: Income ₹5,00,000–₹15,00,000 or investment experience < 5 years\n",
        "- Aggressive: Income > ₹15,00,000 and investment experience ≥ 5 years\n",
        "\n",
        "Generate 5 different strategies to evaluate and then pick up the best one out of\n",
        "\n",
        "What is the customer's risk profile?\n",
        "'''\n",
        "\n",
        "cot_template = PromptTemplate(\n",
        "    input_variables=[\"profile\"],\n",
        "    template=cot_prompt\n",
        ")\n",
        "\n",
        "cust_profile = \"\"\"Profile 1:\n",
        "- Age: 42  \n",
        "- Annual Income: ₹18,00,000  \n",
        "- Investment experience: 8 years  \n",
        "- Primary investment goal: Retirement corpus\"\"\"\n",
        "\n",
        "llm_cot_profile = cot_template | llm\n",
        "\n",
        "response = llm_cot_profile.invoke({'profile': cust_profile})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "<pre>'Let’s evaluate each investment plan based on the investor’s requirements:\\n\\n### Investor’s Preferences Recap\\n- **Capital safety:** Important\\n- **Prefers returns higher than FD**\\n- **Moderate risk acceptable**\\n- **Investment horizon:** 3 years\\n- **Amount:** ₹5,00,000\\n\\n---\\n\\n## Option A: Invest all in Equity Mutual Fund\\n\\n**Risk:**  \\n- **High risk:** Equity mutual funds are market-linked. Short-term volatility (3 years) is high; possibility of negative returns.\\n\\n**Capital Safety:**  \\n- **Low capital safety:** Principal is not guaranteed. There is a risk of capital loss, especially in a short time frame.\\n\\n**Returns Potential:**  \\n- **High returns possible:** Historically, equity funds can give 10-15% annual returns over long periods. For 3 years, returns are unpredictable and can be negative.\\n\\n**Suitability:**  \\n- Fails on capital safety.\\n- Exceeds risk tolerance (moderate risk preferred).\\n- Returns could be higher than FD, but not guaranteed.\\n\\n---\\n\\n## Option B: 50% Fixed Deposit, 50% Gold ETF\\n\\n**Risk:**  \\n- **FD:** Very low risk; principal protected.\\n- **Gold ETF:** Moderate risk; prices fluctuate, but gold is relatively stable compared to equities.\\n\\n**Capital Safety:**  \\n- **FD:** Safe.\\n- **Gold ETF:** No principal guarantee, but historically gold holds value over 3 years, though it can fluctuate.\\n\\n**Returns Potential:**  \\n- **FD:** 6-7% p.a. (approximate for 3-year tenure).\\n- **Gold ETF:** Historically 7-10% p.a., but can vary (may outperform FD).\\n- **Combined:** Weighted average returns should be higher than FD alone.\\n\\n**Suitability:**  \\n- Meets capital safety partially (half is fully safe, half is moderately safe).\\n- Returns likely to be better than FD.\\n- Risk is moderate and diversified.\\n\\n---\\n\\n## Option C: 70% Gold ETF, 30% Fixed Deposit\\n\\n**Risk:**  \\n- **Higher allocation to Gold ETF:** Overall risk is slightly higher than Option B, but still moderate compared to equity.\\n\\n**Capital Safety:**  \\n- **FD portion (30%)** is safe.\\n- **Gold ETF (70%)** is market-linked, but gold tends to be less volatile than equities, and capital loss risk is lower, though not zero.\\n\\n**Returns Potential:**  \\n- **Weighted returns:** More tilted towards gold’s performance. If gold does well, overall returns can be meaningfully higher than FD.\\n- **Still higher than FD, but not as high as equity funds in a bull market.**\\n\\n**Suitability:**  \\n- Capital safety: Majority is in gold, which is moderately safe, and a small portion is in FD (very safe).\\n- Risk: Moderate, slightly higher than Option B.\\n- Returns: Potentially higher than Option B if gold performs well.\\n\\n---\\n\\n## **Comparative Table**\\n\\n| Option | Risk Level    | Capital Safety         | Returns Potential       | Meets Investor Needs? |\\n|--------|--------------|-----------------------|------------------------|-----------------------|\\n| A      | High         | Low                   | High (unpredictable)   | No (too risky)        |\\n| B      | Moderate     | Moderate (FD safe)    | Moderate-to-good       | Yes                   |\\n| C      | Moderate     | Moderate (more gold)  | Moderate-to-high       | Yes                   |\\n\\n---\\n\\n## **Selection and Reasoning**\\n\\n### **Stepwise Reasoning:**\\n1. **Option A** fails on capital safety and risk, so it is ruled out.\\n2. **Option B** offers a balanced approach—half in FD (capital safety), half in Gold ETF (potentially higher returns, moderate risk). This aligns closely with the investor’s desire for moderate risk, some capital safety, and better-than-FD returns.\\n3. **Option C** increases risk slightly by allocating more to Gold ETF. If the investor is comfortable with gold’s market risk and believes gold will perform well, returns can be higher. However, it reduces the “capital safety” element.\\n\\n### **Best Option: Option B**\\n\\n**Why Option B?**\\n- **Diversification:** Reduces overall risk by splitting between two uncorrelated assets (FD and gold).\\n- **Capital Safety:** 50% is fully protected, 50% is moderately safe.\\n- **Returns:** Weighted average likely higher than FD, and not exposed to equity volatility.\\n- **Risk:** Moderate and in line with investor’s comfort.\\n\\n**Option C** could be considered if the investor is slightly more risk tolerant and bullish on gold.  \\nBut **Option B** best fits the stated preferences.\\n\\n---\\n\\n## **Final Recommendation: Option B**\\n\\n> **Split ₹5,00,000 as ₹2,50,000 in Fixed Deposit and ₹2,50,000 in Gold ETF.**\\n\\nThis plan offers moderate risk, some capital safety, and the potential for returns higher than a fixed deposit—matching the investor’s requirements.  \\n**Reasoning:** Balanced allocation, moderate risk, partial capital safety, and higher returns potential than FD alone.'</pre>"
          },
          "execution_count": 67,
          "metadata": {}
        }
      ],
      "source": [
        "tot_prompt = \"\"\"Given the following investor's requirement and preferences:\n",
        "{invest_profile}\n",
        "\n",
        "Options:\n",
        "- Equity Mutual Fund: High risk, high returns\n",
        "- Fixed Deposit: Low risk, moderate returns\n",
        "- Gold ETF: Medium risk, moderate returns\n",
        "\n",
        "Let’s think through multiple possible investment plans:\n",
        "1. Option A: Invest all in Equity Mutual Fund\n",
        "2. Option B: Split 50% in Fixed Deposit and 50% in Gold ETF\n",
        "3. Option C: 70% in Gold ETF, 30% in Fixed Deposit\n",
        "\n",
        "For each option:\n",
        "- Evaluate risk\n",
        "- Check if capital safety is acceptable\n",
        "- Compare returns potential\n",
        "\n",
        "Now, select the best option based on these evaluations.  \n",
        "Explain the reasoning path you took.\n",
        "\"\"\"\n",
        "\n",
        "tot_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"invest_profile\"],\n",
        "    template=tot_prompt\n",
        ")\n",
        "\n",
        "investor_profile = \"\"\"An investor wants to invest ₹5,00,000 for 3 years.  \n",
        "The investor's preferences:\n",
        "- Capital safety is important\n",
        "- Prefers returns higher than fixed deposit\n",
        "- Moderate risk acceptable\"\"\"\n",
        "\n",
        "llm_with_tot = tot_prompt_template | llm\n",
        "response = llm_with_tot.invoke({'invest_profile': investor_profile})\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": "\n<div className=\"bg-white p-4 rounded shadow\"> <pre className=\"whitespace-pre-wrap text-black\">Let&#x2019;s evaluate each investment plan based on the investor&#x2019;s requirements:<br/><br/>### Investor&#x2019;s Preferences Recap<br/>- **Capital safety:** Important<br/>- **Prefers returns higher than FD**<br/>- **Moderate risk acceptable**<br/>- **Investment horizon:** 3 years<br/>- **Amount:** &#x20B9;5,00,000<br/><br/>---<br/><br/>## Option A: Invest all in Equity Mutual Fund<br/><br/>**Risk:**  <br/>- **High risk:** Equity mutual funds are market-linked. Short-term volatility (3 years) is high; possibility of negative returns.<br/><br/>**Capital Safety:**  <br/>- **Low capital safety:** Principal is not guaranteed. There is a risk of capital loss, especially in a short time frame.<br/><br/>**Returns Potential:**  <br/>- **High returns possible:** Historically, equity funds can give 10-15% annual returns over long periods. For 3 years, returns are unpredictable and can be negative.<br/><br/>**Suitability:**  <br/>- Fails on capital safety.<br/>- Exceeds risk tolerance (moderate risk preferred).<br/>- Returns could be higher than FD, but not guaranteed.<br/><br/>---<br/><br/>## Option B: 50% Fixed Deposit, 50% Gold ETF<br/><br/>**Risk:**  <br/>- **FD:** Very low risk; principal protected.<br/>- **Gold ETF:** Moderate risk; prices fluctuate, but gold is relatively stable compared to equities.<br/><br/>**Capital Safety:**  <br/>- **FD:** Safe.<br/>- **Gold ETF:** No principal guarantee, but historically gold holds value over 3 years, though it can fluctuate.<br/><br/>**Returns Potential:**  <br/>- **FD:** 6-7% p.a. (approximate for 3-year tenure).<br/>- **Gold ETF:** Historically 7-10% p.a., but can vary (may outperform FD).<br/>- **Combined:** Weighted average returns should be higher than FD alone.<br/><br/>**Suitability:**  <br/>- Meets capital safety partially (half is fully safe, half is moderately safe).<br/>- Returns likely to be better than FD.<br/>- Risk is moderate and diversified.<br/><br/>---<br/><br/>## Option C: 70% Gold ETF, 30% Fixed Deposit<br/><br/>**Risk:**  <br/>- **Higher allocation to Gold ETF:** Overall risk is slightly higher than Option B, but still moderate compared to equity.<br/><br/>**Capital Safety:**  <br/>- **FD portion (30%)** is safe.<br/>- **Gold ETF (70%)** is market-linked, but gold tends to be less volatile than equities, and capital loss risk is lower, though not zero.<br/><br/>**Returns Potential:**  <br/>- **Weighted returns:** More tilted towards gold&#x2019;s performance. If gold does well, overall returns can be meaningfully higher than FD.<br/>- **Still higher than FD, but not as high as equity funds in a bull market.**<br/><br/>**Suitability:**  <br/>- Capital safety: Majority is in gold, which is moderately safe, and a small portion is in FD (very safe).<br/>- Risk: Moderate, slightly higher than Option B.<br/>- Returns: Potentially higher than Option B if gold performs well.<br/><br/>---<br/><br/>## **Comparative Table**<br/><br/>| Option | Risk Level    | Capital Safety         | Returns Potential       | Meets Investor Needs? |<br/>|--------|--------------|-----------------------|------------------------|-----------------------|<br/>| A      | High         | Low                   | High (unpredictable)   | No (too risky)        |<br/>| B      | Moderate     | Moderate (FD safe)    | Moderate-to-good       | Yes                   |<br/>| C      | Moderate     | Moderate (more gold)  | Moderate-to-high       | Yes                   |<br/><br/>---<br/><br/>## **Selection and Reasoning**<br/><br/>### **Stepwise Reasoning:**<br/>1. **Option A** fails on capital safety and risk, so it is ruled out.<br/>2. **Option B** offers a balanced approach&#x2014;half in FD (capital safety), half in Gold ETF (potentially higher returns, moderate risk). This aligns closely with the investor&#x2019;s desire for moderate risk, some capital safety, and better-than-FD returns.<br/>3. **Option C** increases risk slightly by allocating more to Gold ETF. If the investor is comfortable with gold&#x2019;s market risk and believes gold will perform well, returns can be higher. However, it reduces the &#x201C;capital safety&#x201D; element.<br/><br/>### **Best Option: Option B**<br/><br/>**Why Option B?**<br/>- **Diversification:** Reduces overall risk by splitting between two uncorrelated assets (FD and gold).<br/>- **Capital Safety:** 50% is fully protected, 50% is moderately safe.<br/>- **Returns:** Weighted average likely higher than FD, and not exposed to equity volatility.<br/>- **Risk:** Moderate and in line with investor&#x2019;s comfort.<br/><br/>**Option C** could be considered if the investor is slightly more risk tolerant and bullish on gold.  <br/>But **Option B** best fits the stated preferences.<br/><br/>---<br/><br/>## **Final Recommendation: Option B**<br/><br/>&gt; **Split &#x20B9;5,00,000 as &#x20B9;2,50,000 in Fixed Deposit and &#x20B9;2,50,000 in Gold ETF.**<br/><br/>This plan offers moderate risk, some capital safety, and the potential for returns higher than a fixed deposit&#x2014;matching the investor&#x2019;s requirements.  <br/>**Reasoning:** Balanced allocation, moderate risk, partial capital safety, and higher returns potential than FD alone.<br/></pre></div>"
          },
          "execution_count": 68,
          "metadata": {}
        }
      ],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}