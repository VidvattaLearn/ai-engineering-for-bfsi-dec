{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "os.environ[\"OPENAI_API_VERSION\"] = \"open-api-version\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"endpoint\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"api-key\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "  deployment_name = \"gpt-4.1\",\n",
        "  temperature=1,\n",
        "  top_p=0.8\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = llm.invoke('tell me about ai agents in 10 words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# temperature = 0\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# temperature = 0\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# temperature = 0\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# temperature = 0\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "llm = AzureChatOpenAI(\n",
        "  deployment_name = \"gpt-4.1\",\n",
        "  temperature=1,\n",
        "  top_p=0.8,\n",
        "  # max_tokens=5\n",
        ")\n",
        "\n",
        "response = llm.invoke('tell me about ai agents in 10 words')\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# zero shot \n",
        "resposne = llm.invoke(\"\"\"\n",
        "Write three short, punchy email subject lines to announce the launch of a new premium research report on global consumer trends. \n",
        "Keep them ≤ 60 characters and professional. this will be processed using python so give it in list form\n",
        "\"\"\")\n",
        "print(resposne.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "few_shot_prompts = \"\"\"\n",
        "Example 1:\n",
        "Product: \"Holiday Shopping Index\"\n",
        "Subjects:\n",
        "- \"Holiday Shopping Index — What Changed\"\n",
        "- \"Top Holiday Trends You Need to Know\"\n",
        "- \"New: 2025 Holiday Shopping Index\"\n",
        "\n",
        "Example 2:\n",
        "Product: \"Ad Effectiveness Toolkit\"\n",
        "Subjects:\n",
        "- \"Boost ROI: Ad Effectiveness Toolkit\"\n",
        "- \"New Toolkit — Measure Ad Impact Faster\"\n",
        "- \"Get the Ad Effectiveness Playbook\"\n",
        "\n",
        "Example 3:\n",
        "Product: \"Gen Z Buying Signals\"\n",
        "Subjects:\n",
        "- \"Gen Z Buying Signals — Download Now\"\n",
        "- \"What Gen Z Wants in 2025\"\n",
        "- \"New Report: Gen Z Purchase Triggers\"\n",
        "\n",
        "Now: Product: \"Global Consumer Trends Report\"\n",
        "Write three short, punchy email subject lines. Keep them ≤ 60 characters, professional, and include a strong action word.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "resposne = llm.invoke(few_shot_prompts)\n",
        "print(resposne.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summarization\n",
        "context = \"\"\"Input Text: Artificial Intelligence (AI) has become a transformative technology in numerous industries. Its applications range from healthcare, where AI is used to improve diagnostics and personalize patient care, to finance, where it helps in fraud detection and automated trading. As AI continues to evolve, \n",
        "it is poised to revolutionize traditional industries, creating smarter, more efficient systems. \"\"\"\n",
        "\n",
        "prompt = \"Summarize in 3 bullet points. each bullet point should be less than 100 characters\"\n",
        "\n",
        "\n",
        "resposne = llm.invoke(context + '\\n' + prompt)\n",
        "print(resposne.content)\n",
        "\n",
        "\n",
        "## Code Generation\n",
        "\n",
        "prompt  = \"Write a Python function that takes a list of integers and returns the sum of all even numbers, only respond with a code\"\n",
        "\n",
        "resposne = llm.invoke(prompt)\n",
        "print(resposne.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Question Answering\n",
        "\n",
        "question = \"Question: What are the primary causes of climate change?\"\n",
        "\n",
        "\n",
        "while (True):\n",
        "  \n",
        "  question = input(\"Enter the question\")\n",
        "  context = f\"\"\"Context: \"The global climate change crisis is primarily driven by human activities, including the burning of fossil fuels which \n",
        "  increases the concentration of greenhouse gases in the atmosphere. This leads to rising temperatures, more severe weather patterns,\n",
        "  and disruptions in ecosystems.\"\n",
        "  \n",
        "  {question}\"\"\"\n",
        "\n",
        "  resposne = llm.invoke(context)\n",
        "  print(resposne.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Extraction\n",
        "\n",
        "prompt = \"\"\"Input: \"John Smith, born on April 15, 1985, works as a software engineer at InnovateTech, located at 1234 Tech Lane, \n",
        "San Francisco, CA.\" Prompt: \n",
        "Extract the person's name, date of birth, job title, and company from the following text.\"\"\"\n",
        "\n",
        "resposne = llm.invoke(prompt)\n",
        "print(resposne.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "resposne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pydantic import BaseModel, Field\n",
        "class PersonDetails(BaseModel):\n",
        "    \"\"\"Always use this tool to structure your response to the user.\"\"\"\n",
        "    person_name: str = Field(description=\"Name of the person\")\n",
        "    date_of_birth: str = Field(description=\"date of birth\")\n",
        "    job_title: str = Field(\"Job Title\")\n",
        "    company: str = Field(\"Company\")\n",
        "    joining_date: str = Field(\"get joining date from the text, it should be a date\")\n",
        "\n",
        "\n",
        "model_with_structured_output = llm.with_structured_output(PersonDetails)\n",
        "\n",
        "response = model_with_structured_output.invoke(prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "response.date_of_birth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Person(BaseModel):\n",
        "    name: str = Field(description=\"name of the person being discussed\")\n",
        "    title: str = Field(description=\"job title of the person being discussed\")\n",
        "\n",
        "# 2. Define the outer model, which includes a list of the nested model\n",
        "class People(BaseModel):\n",
        "    people: list[Person] = Field(description=\"a list of people and their related fields mentioned in the text\")\n",
        "\n",
        "model_with_structured_output = llm.with_structured_output(People)\n",
        "\n",
        "response = model_with_structured_output.invoke(\"two people mr rajesh malhotra and miss sharmila sharma went to party\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "cot_prompt = '''\n",
        "Given the following customer's financial profile:\n",
        "{profile}  \n",
        "\n",
        "Risk profile classification:\n",
        "- Conservative: Income < ₹5,00,000 or no investment experience\n",
        "- Moderate: Income ₹5,00,000–₹15,00,000 or investment experience < 5 years\n",
        "- Aggressive: Income > ₹15,00,000 and investment experience ≥ 5 years\n",
        "\n",
        "Let’s reason step by step:\n",
        "1. Check income threshold.\n",
        "2. Check investment experience.\n",
        "3. Apply both criteria to classify.\n",
        "\n",
        "\n",
        "\n",
        "What is the customer's risk profile?\n",
        "'''\n",
        "\n",
        "cot_template = PromptTemplate(\n",
        "    input_variables=[\"profile\"],\n",
        "    template=cot_prompt\n",
        ")\n",
        "\n",
        "cust_profile = \"\"\"Profile 1:\n",
        "- Age: 42  \n",
        "- Annual Income: ₹18,00,000  \n",
        "- Investment experience: 8 years  \n",
        "- Primary investment goal: Retirement corpus\"\"\"\n",
        "\n",
        "llm_cot_profile = cot_template | llm\n",
        "\n",
        "response = llm_cot_profile.invoke({'profile': cust_profile})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Self Consistency\n",
        "\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "cot_prompt = '''\n",
        "You are financial risk expert\n",
        "Given the following customer's financial profile:\n",
        "{profile}  \n",
        "\n",
        "Risk profile classification:\n",
        "- Conservative: Income < ₹5,00,000 or no investment experience\n",
        "- Moderate: Income ₹5,00,000–₹15,00,000 or investment experience < 5 years\n",
        "- Aggressive: Income > ₹15,00,000 and investment experience ≥ 5 years\n",
        "\n",
        "Generate 5 different strategies to evaluate and then pick up the best one out of\n",
        "\n",
        "What is the customer's risk profile?\n",
        "'''\n",
        "\n",
        "cot_template = PromptTemplate(\n",
        "    input_variables=[\"profile\"],\n",
        "    template=cot_prompt\n",
        ")\n",
        "\n",
        "cust_profile = \"\"\"Profile 1:\n",
        "- Age: 42  \n",
        "- Annual Income: ₹18,00,000  \n",
        "- Investment experience: 8 years  \n",
        "- Primary investment goal: Retirement corpus\"\"\"\n",
        "\n",
        "llm_cot_profile = cot_template | llm\n",
        "\n",
        "response = llm_cot_profile.invoke({'profile': cust_profile})\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tot_prompt = \"\"\"Given the following investor's requirement and preferences:\n",
        "{invest_profile}\n",
        "\n",
        "Options:\n",
        "- Equity Mutual Fund: High risk, high returns\n",
        "- Fixed Deposit: Low risk, moderate returns\n",
        "- Gold ETF: Medium risk, moderate returns\n",
        "\n",
        "Let’s think through multiple possible investment plans:\n",
        "1. Option A: Invest all in Equity Mutual Fund\n",
        "2. Option B: Split 50% in Fixed Deposit and 50% in Gold ETF\n",
        "3. Option C: 70% in Gold ETF, 30% in Fixed Deposit\n",
        "\n",
        "For each option:\n",
        "- Evaluate risk\n",
        "- Check if capital safety is acceptable\n",
        "- Compare returns potential\n",
        "\n",
        "Now, select the best option based on these evaluations.  \n",
        "Explain the reasoning path you took.\n",
        "\"\"\"\n",
        "\n",
        "tot_prompt_template = PromptTemplate(\n",
        "    input_variables=[\"invest_profile\"],\n",
        "    template=tot_prompt\n",
        ")\n",
        "\n",
        "investor_profile = \"\"\"An investor wants to invest ₹5,00,000 for 3 years.  \n",
        "The investor's preferences:\n",
        "- Capital safety is important\n",
        "- Prefers returns higher than fixed deposit\n",
        "- Moderate risk acceptable\"\"\"\n",
        "\n",
        "llm_with_tot = tot_prompt_template | llm\n",
        "response = llm_with_tot.invoke({'invest_profile': investor_profile})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
